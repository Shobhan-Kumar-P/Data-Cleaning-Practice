{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPmlR2okDEdLq/MqOo4yeX6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shobhan-Kumar-P/Data-Cleaning-Practice/blob/main/Complete_LLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BJ6a_gVR86Nx"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import tiktoken\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import tqdm\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = tiktoken.get_encoding(\"gpt2\")"
      ],
      "metadata": {
        "id": "seLm6ClG9iVg"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def text_to_token_ids(data, tokenizer):\n",
        "  encoded = tokenizer.encode(data, allowed_special = {\"<|endoftext|>\"})\n",
        "  encoded = torch.tensor(encoded).unsqueeze(0)\n",
        "  return encoded\n",
        "\n",
        "def token_ids_to_text(encoded, tokenizer):\n",
        "  decoded = encoded.squeeze(0)\n",
        "  decoded = decoded.tolist()\n",
        "  return tokenizer.decode(decoded)"
      ],
      "metadata": {
        "id": "Avq_cXzF9z-Y"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "encoded = torch.tensor(token_ids).unsqueeze(0)\n",
        "You‚Äôre turning a 1D tensor of token IDs (shape [N]) into a 2D tensor (shape [1, N]) ‚Äî this represents a batch of 1 sentence, which is standard input format for models like transformers.\n",
        "\n",
        "PyTorch tensors are not plain Python lists, but the tokenizer.decode() method typically expects a list of integers (not a PyTorch tensor).\n",
        "\n",
        "Because most tokenizers (like Hugging Face or OpenAI tokenizers) expect a list of token IDs, not a PyTorch tensor.\n",
        "\n",
        ".tolist() is a PyTorch (or NumPy) method that converts a tensor into a nested Python list containing standard Python data types like int, float, or bool.\n",
        "\n",
        "‚úÖ So:\n",
        "Yes, .tolist() only works properly on tensors containing numerical or boolean data.\n",
        "\n",
        "‚ùå It does not work on:\n",
        "Tensors with strings (which PyTorch doesn't support anyway)\n",
        "\n",
        "Non-numerical or non-boolean types"
      ],
      "metadata": {
        "id": "v-dZSwuyAaok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GPT_124M = {\n",
        "    \"vocab_size\" : 50257,\n",
        "    \"context_size\" : 1024,\n",
        "    \"emb_dim\" : 768,\n",
        "    \"num_of_heads\" : 12,\n",
        "    \"num_of_layers\" : 12,\n",
        "    \"qkv_bias\" : False,\n",
        "    \"drop_rate\" : 0.1\n",
        "}"
      ],
      "metadata": {
        "id": "Qy9LUYpbE_it"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Multihead_Attention(nn.Module):\n",
        "  def __init__(self, cfg):\n",
        "    super().__init__()\n",
        "    if cfg['emb_dim']%cfg['num_of_heads'] != 0:\n",
        "      raise ValueError(\"number of heads cant divide embedding dimension\")\n",
        "\n",
        "    self.num_of_heads = cfg['num_of_heads']\n",
        "    self.emb_dim = cfg[\"emb_dim\"]\n",
        "    self.context_length = cfg['context_length']\n",
        "    self.head_dim = cfg['emb_dim'] // cfg['num_of_heads']\n",
        "    self.q = nn.Linear(cfg['emb_dim'], cfg['emb_dim'], bias = cfg['qkv_bias'])\n",
        "    self.k = nn.Linear(cfg['emb_dim'], cfg['emb_dim'], bias = cfg['qkv_bias'])\n",
        "    self.v = nn.Linear(cfg['emb_dim'], cfg['emb_dim'], bias = cfg['qkv_bias'])\n",
        "\n",
        "    self.out_proj = nn.Linear(cfg['emb_dim'], cfg['emb_dim'])\n",
        "    self.register_buffer('mask', torch.triu(torch.ones(cfg['context_length'], cfg['context_length']), diagonal = 1))\n",
        "\n",
        "  def forward(self, inputs):\n",
        "    batch, num_of_tokens, d_out = inputs.shape\n",
        "    q = self.q(inputs)\n",
        "    k = self.k(inputs)\n",
        "    v = self.v(inputs)\n",
        "\n",
        "    q = q.view(batch, num_of_tokens, self.num_heads, self.head_dim)\n",
        "    k = k.view(batch, num_of_tokens, self.num_heads, self.head_dim)\n",
        "    v = v.view(batch, num_of_tokens, self.num_heads, self.head_dim)\n",
        "\n",
        "    q = q.transpose(1,2)\n",
        "    k = k.transpose(1,2)\n",
        "    v = v.transpose(1,2)\n",
        "\n",
        "    attention_scores = q @ k.transpose(2,3)\n",
        "    attention_scores.masked_fill_(self.mask.bool()[:num_of_tokens, :num_of_tokens], -torch.inf)\n",
        "\n",
        "    attention_weights = torch.softmax(attention_scores/k.shape[-1], dim = -1)\n",
        "\n",
        "    context_vec = (attention_weights @ v).transpose(1,2)\n",
        "\n",
        "    context_vec = context_vec.contiguous().view(batch, num_of_tokens, self.emb_dim)\n",
        "\n",
        "    context_vec = self.out_proj(context_vec)\n",
        "\n",
        "    return context_vec\n",
        "\n"
      ],
      "metadata": {
        "id": "zSxwuzv9xho0"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Excellent follow-up, GEN ‚Äî this dives deep into the *why* behind `out_proj`. Let's walk step by step to understand **how** `out_proj` adds a learned transformation **after** attention has already done its job.\n",
        "\n",
        "---\n",
        "\n",
        "## üß† You're Right to Ask:\n",
        "\n",
        "> ‚ÄúDidn‚Äôt attention already perform all the transformations? Why do we need more?‚Äù\n",
        "\n",
        "Let‚Äôs clarify what each step actually *does*, and what‚Äôs left for `out_proj`.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚öôÔ∏è Recap of What Attention Has Done So Far:\n",
        "\n",
        "1. **Q, K, V Projections:**\n",
        "   These map input tokens into **query**, **key**, and **value** spaces via learned linear layers:\n",
        "\n",
        "   ```python\n",
        "   queries = W_query(x)\n",
        "   keys = W_key(x)\n",
        "   values = W_value(x)\n",
        "   ```\n",
        "\n",
        "2. **Attention Computation (per head):**\n",
        "   Using `Q @ K.T` to get weights, then `softmax`, then:\n",
        "\n",
        "   ```python\n",
        "   attention_output = attn_weights @ values\n",
        "   ```\n",
        "\n",
        "   This gives you a **weighted summary** for each head.\n",
        "\n",
        "3. **Multi-Head Concatenation:**\n",
        "\n",
        "   ```python\n",
        "   context_vec = context_vec.view(batch, seq_len, d_out)\n",
        "   ```\n",
        "\n",
        "   Now, you‚Äôve just **stacked** head outputs side by side.\n",
        "\n",
        "---\n",
        "\n",
        "### üî• What Hasn‚Äôt Happened Yet:\n",
        "\n",
        "Each head is still **independent** in the concatenated vector. Nothing so far has learned:\n",
        "\n",
        "* **How much to trust each head**\n",
        "* **Which heads‚Äô outputs to mix**\n",
        "* **Which combinations of heads are useful**\n",
        "\n",
        "That‚Äôs where `out_proj` comes in.\n",
        "\n",
        "---\n",
        "\n",
        "### üß¨ What `out_proj` Actually Does:\n",
        "\n",
        "This is a **learned linear transformation**:\n",
        "\n",
        "```python\n",
        "out_proj = nn.Linear(d_out, d_out)\n",
        "```\n",
        "\n",
        "Which means:\n",
        "\n",
        "```python\n",
        "context_vec = context_vec @ W_out.T + b\n",
        "```\n",
        "\n",
        "Where:\n",
        "\n",
        "* `W_out ‚àà ‚Ñù^{d_out √ó d_out}` is a weight matrix\n",
        "* `b ‚àà ‚Ñù^{d_out}` is a bias term\n",
        "\n",
        "It‚Äôs like a **fully connected layer** applied to every token's final attention vector.\n",
        "\n",
        "---\n",
        "\n",
        "### üí° Why Is This Useful?\n",
        "\n",
        "Because:\n",
        "\n",
        "* Attention only gives you **head-wise outputs**.\n",
        "* `out_proj` lets the model learn **head interactions** across dimensions.\n",
        "* It adds **learnable flexibility** to reinterpret or remix those outputs.\n",
        "\n",
        "In deep networks, even small transformations matter ‚Äî especially learnable ones.\n",
        "\n",
        "---\n",
        "\n",
        "### üìä Example:\n",
        "\n",
        "Imagine:\n",
        "\n",
        "* `num_heads = 4`\n",
        "* `head_dim = 8`\n",
        "* So `d_out = 32`\n",
        "\n",
        "The result after concatenating heads is a 32-dim vector:\n",
        "\n",
        "```\n",
        "[ h1_output | h2_output | h3_output | h4_output ]\n",
        "```\n",
        "\n",
        "But maybe some heads are redundant, or combinations matter (e.g., h1 - h3).\n",
        "The `out_proj` layer learns to produce a **better version** of this 32-dim vector by **remixing the components**.\n",
        "\n",
        "---\n",
        "\n",
        "### ‚úÖ Final Summary:\n",
        "\n",
        "| Step              | Purpose                                                   |\n",
        "| ----------------- | --------------------------------------------------------- |\n",
        "| Attention         | Learns **which tokens** to focus on                       |\n",
        "| Multi-head concat | Gathers different attention perspectives                  |\n",
        "| `out_proj`        | Learns how to **combine/mix/reweight** those perspectives |\n",
        "\n",
        "---\n",
        "\n",
        "If you'd like, I can show a simple example with fake data to see how `out_proj` changes the output numerically. Want to?\n"
      ],
      "metadata": {
        "id": "IdwgQ2JGjmXi"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G3UM0KkqpZYX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}